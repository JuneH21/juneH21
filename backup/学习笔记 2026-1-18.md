**cnn初步认识：**
****
阅读文章：https://poloclub.github.io/cnn-explainer/
****

> 输入层（input）
输入数据

> 卷积层（convolution layer）
<img width="468" height="243" alt="Image" src="https://github.com/user-attachments/assets/23925186-4b38-4e03-8ed4-07d3789e6fd0" />

1. 卷积层是 CNN 的基础，因为它们包含了学习到的核（权重），这些核能提取区分不同图像的特征
2. 卷积神经元对应的核和前一层对应神经元的输出进行元素逐元素的点积。这将产生与唯一核数相同的中间结果。卷积神经元是所有中间结果与学习偏差加在一起的结果。
3. bias：偏置

> 超参数（hyper-parameter）

<img width="682" height="342" alt="Image" src="https://github.com/user-attachments/assets/2cb7ab32-7882-4dad-bd16-fdf5187bc2bc" />
如图所示，以上参数由开发员手动输入：

1. 输入大小（input size）
2. 是否扩展（padding）
3. 卷积核大小（kernal size）
4. 步频（stride）

> 激活函数
`ReLU`

<img width="533" height="533" alt="Image" src="https://github.com/user-attachments/assets/b02ef9a4-7547-46de-8535-13858cacd723" />

> soft max

<img width="252" height="75" alt="Image" src="https://github.com/user-attachments/assets/48d20369-6a11-4d7d-9834-a5e1d6d3b92e" />

数学公式
<img width="669" height="391" alt="Image" src="https://github.com/user-attachments/assets/82f7b45e-5eac-4625-bd03-fd606c7c016f" />

作用：确保 CNN 输出总和为 1。因此，软极大作对于将模型输出缩放为概率非常有用。

> pooling layer
逐步缩小网络的空间范围，从而减少网络的参数和整体计算量

> Flatten Layer
该层将网络中的三维层转换为一维矢量，以适应全连通层的输入进行分类。在最后会用到。